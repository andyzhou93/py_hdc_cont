{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import hdc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numIter = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runIterSeeded(seed):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    import sys\n",
    "    sys.path.append('/Users/andy/Research/py_hdc_cont/hdc_scripts')\n",
    "\n",
    "    import hdc\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    isTrain = np.empty(0)\n",
    "    trainTrials = np.random.randint(0,numTrial,numGest)\n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            if t == trainTrials[g]:\n",
    "                isTrain = np.concatenate((isTrain,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "            else:\n",
    "                isTrain = np.concatenate((isTrain,np.zeros(numEx)))\n",
    "    trainTrials = np.random.randint(0,numTrial,numGest)\n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            if t == trainTrials[g]:\n",
    "                isTrain = np.concatenate((isTrain,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "            else:\n",
    "                isTrain = np.concatenate((isTrain,np.zeros(numEx)))\n",
    "\n",
    "    featData = pd.read_feather('/Users/andy/Research/py_hdc_cont/hdc_scripts/S' + str(subject) + '_feature.df')\n",
    "    ngramData = pd.read_feather('/Users/andy/Research/py_hdc_cont/hdc_scripts/S' + str(subject) + '_ngram.df')\n",
    "\n",
    "    featData['isTrain'] = isTrain\n",
    "    ngramData['isTrain'] = isTrain\n",
    "\n",
    "    # train HD model\n",
    "    allGest = ngramData['gesture'].unique()\n",
    "    \n",
    "    # loop through all HDC adaptive thresholds\n",
    "    accHDC = np.zeros(len(adaptThreshold))\n",
    "    numHDC = np.zeros(len(adaptThreshold))\n",
    "    for atIdx,at in enumerate(adaptThreshold):\n",
    "        AM = hdc.Memory(D)\n",
    "        for g in allGest:\n",
    "            ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTrain'] == 1) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "            AM.train_sub_cluster(ng,vClass=g,threshold=at)\n",
    "            AM.prune(min=5)\n",
    "\n",
    "        for g in allGest:\n",
    "            ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTrain'] == 1) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "            AM.train_sub_cluster(ng,vClass=g,threshold=at)\n",
    "            AM.prune(min=5)\n",
    "            \n",
    "        # collect testing data and perform inference\n",
    "        testNgram = ngramData.loc[(ngramData['isTrain'] == 0)].iloc[:,0:D]\n",
    "        testLabel = ngramData.loc[(ngramData['isTrain'] == 0)].iloc[:,D]\n",
    "        label,sim = AM.match(np.asarray(testNgram),bipolar=True)\n",
    "        accHDC[atIdx] = (label == np.asarray(testLabel)).sum()/len(label)\n",
    "        numHDC[atIdx] = len(AM.classes)\n",
    "\n",
    "    # train and test SVM model\n",
    "    clf = svm.SVC(decision_function_shape='ovo',kernel='linear',C=1)\n",
    "    clf.fit(featData.loc[featData['isTrain'] == 1].iloc[:,0:numFeat],featData.loc[featData['isTrain'] == 1].iloc[:,numFeat])\n",
    "    yhat = clf.predict(featData.loc[featData['isTrain'] == 0].iloc[:,0:numFeat])\n",
    "    accSVM = accuracy_score(yhat,featData.loc[featData['isTrain'] == 0].iloc[:,numFeat])\n",
    "    numSVM = len(clf.support_)\n",
    "\n",
    "    return accHDC, numHDC, accSVM, numSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "dview = client[:]\n",
    "\n",
    "# segment only the hold portions of data\n",
    "holdStart = 70\n",
    "holdEnd = 149\n",
    "numEx = holdEnd - holdStart + 1\n",
    "\n",
    "# hypervector and feature dimensions\n",
    "D = 10000\n",
    "numFeat = 320\n",
    "numGest = 13\n",
    "numTrial = 5\n",
    "\n",
    "# testPercentage = np.linspace(0.05,1,20)\n",
    "# adaptThreshold = np.linspace(0.05,0.8,16)\n",
    "testPercentage = np.linspace(0.1,0.8,2)\n",
    "adaptThreshold = np.linspace(0.2,0.5,2)\n",
    "\n",
    "numSVM = np.zeros((5,len(testPercentage),numIter))\n",
    "accSVM = np.zeros((5,len(testPercentage),numIter))\n",
    "\n",
    "numHDC = np.zeros((5,len(testPercentage),len(adaptThreshold),numIter))\n",
    "accHDC = np.zeros((5,len(testPercentage),len(adaptThreshold),numIter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = 2\n",
    "\n",
    "runData = {}\n",
    "runData['numTrial'] = numTrial\n",
    "runData['numGest'] = numGest\n",
    "runData['numEx'] = numEx\n",
    "runData['adaptThreshold'] = adaptThreshold\n",
    "runData['D'] = D\n",
    "runData['numFeat'] = numFeat\n",
    "runData['subject'] = subject\n",
    "dview.push(runData,block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 0.100000 of single trial for training\n",
      "\tTook 12.854424 seconds\n",
      "Running with 0.800000 of single trial for training\n",
      "\tTook 17.743298 seconds\n"
     ]
    }
   ],
   "source": [
    "# loop through different testing percentages\n",
    "for tpIdx,tp in enumerate(testPercentage):\n",
    "    dview.push({'tp':tp},block=True)\n",
    "\n",
    "    lview = client.load_balanced_view()\n",
    "    lview.block = True\n",
    "\n",
    "    print('Running with %f of single trial for training' % (tp))\n",
    "    startTime = time.time()\n",
    "    res = lview.map(runIterSeeded, range(numIter))\n",
    "    stopTime = time.time()\n",
    "    print('\\tTook %f seconds' % (stopTime - startTime))\n",
    "    \n",
    "    for i in range(numIter):\n",
    "        accSVM[subject-1,tpIdx,i] = res[i][2]\n",
    "        accSVM[subject-1,tpIdx,i] = res[i][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.93305288, 0.91778846]), array([13., 31.]), 0.9626201923076924, 442)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in range(numIter):\n",
    "        accSVM[s,i,j] = res[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
