{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import hdc\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "importlib.reload(hdc)\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data for Subject 2\n",
      "Running with 0.100000 of single trial for training\n",
      "Finished iteration 2, average time 4.917526 seconds\n",
      "Running with 1.000000 of single trial for training\n",
      "Finished iteration 2, average time 254.639532 seconds\n"
     ]
    }
   ],
   "source": [
    "# location of all offline data\n",
    "dataDir = './emg_mat/offline/'\n",
    "\n",
    "# choose experiments for base and new context\n",
    "baseExperiment = 1\n",
    "newExperiment = 3\n",
    "\n",
    "# segment only the hold portions of data\n",
    "holdStart = 70\n",
    "holdEnd = 149\n",
    "numEx = holdEnd - holdStart + 1\n",
    "\n",
    "# hypervector and feature dimensions\n",
    "D = 10000\n",
    "numFeat = 320\n",
    "\n",
    "\n",
    "numIter = 2\n",
    "# testPercentage = np.linspace(0.05,1,20)\n",
    "# adaptThreshold = np.linspace(0.05,0.8,16)\n",
    "testPercentage = np.linspace(0.1,1,2)\n",
    "adaptThreshold = np.linspace(0.2,0.75,2)\n",
    "\n",
    "numSVM = np.zeros((len(testPercentage),numIter))\n",
    "accSVM = np.zeros((len(testPercentage),numIter))\n",
    "\n",
    "numHDC = np.zeros((len(testPercentage),len(adaptThreshold),numIter))\n",
    "accHDC = np.zeros((len(testPercentage),len(adaptThreshold),numIter))\n",
    "\n",
    "# subject labels are 1-indexed\n",
    "subject = 2\n",
    "print('Gathering data for Subject ' + str(subject))\n",
    "\n",
    "# load data from the two contexts\n",
    "filename = dataDir + 'S' + str(subject) + 'E' + str(baseExperiment) + '.mat'\n",
    "base = sio.loadmat(filename)['emgHD']\n",
    "filename = dataDir + 'S' + str(subject) + 'E' + str(newExperiment) + '.mat'\n",
    "new = sio.loadmat(filename)['emgHD']\n",
    "\n",
    "# get metatdata\n",
    "numGest, numTrial = base.shape\n",
    "numCh = base[0,0][2].shape[1]\n",
    "\n",
    "# collect all data and as single dataframe\n",
    "features = np.empty((numCh*5,0))\n",
    "ngrams = np.empty((D,0))\n",
    "labels = np.empty(0)\n",
    "trials = np.empty(0)\n",
    "context = np.empty(0)\n",
    "\n",
    "# collect baseline data\n",
    "for g in range(numGest):\n",
    "    for t in range(numTrial):\n",
    "        trial = base[g,t]\n",
    "        feat = np.empty((0,numEx))\n",
    "        for i in range(5):\n",
    "            feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "        features = np.concatenate((features,feat),axis=1)\n",
    "        ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "        labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "        trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "        context = np.concatenate((context,0*np.ones(numEx)))\n",
    "\n",
    "# collect new data\n",
    "for g in range(numGest):\n",
    "    for t in range(numTrial):\n",
    "        trial = new[g,t]\n",
    "        feat = np.empty((0,numEx))\n",
    "        for i in range(5):\n",
    "            feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "        features = np.concatenate((features,feat),axis=1)\n",
    "        ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "        labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "        trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "        context = np.concatenate((context,1*np.ones(numEx)))\n",
    "\n",
    "# create dataframe for features\n",
    "featCols = ['feature' + str(i) for i in range(features.shape[0])]\n",
    "featData = pd.DataFrame(features.T,columns=featCols)\n",
    "featData['gesture'] = labels\n",
    "featData['trial'] = trials\n",
    "featData['context'] = context\n",
    "\n",
    "# create dataframe for ngrams\n",
    "ngramCols = ['hv' + str(i) for i in range(ngrams.shape[0])]\n",
    "ngramData = pd.DataFrame(ngrams.T,columns=ngramCols)\n",
    "ngramData['gesture'] = labels\n",
    "ngramData['trial'] = trials\n",
    "ngramData['context'] = context\n",
    "\n",
    "# loop through different testing percentages\n",
    "for tpIdx,tp in enumerate(testPercentage):\n",
    "    print('Running with %f of single trial for training' % (tp))\n",
    "    # iterate through to get averages (different cross-validation folds)\n",
    "    elapsedTime = 0\n",
    "    for n in range(numIter):\n",
    "        startTime = time.time()\n",
    "        isTrain = np.empty(0)\n",
    "        testTrials = np.random.randint(0,numTrial,numGest)\n",
    "        for g in range(numGest):\n",
    "            for t in range(numTrial):\n",
    "                if t != testTrials[g]:\n",
    "                    isTrain = np.concatenate((isTrain,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "                else:\n",
    "                    isTrain = np.concatenate((isTrain,np.zeros(numEx)))\n",
    "        testTrials = np.random.randint(0,numTrial,numGest)\n",
    "        for g in range(numGest):\n",
    "            for t in range(numTrial):\n",
    "                if t != testTrials[g]:\n",
    "                    isTrain = np.concatenate((isTrain,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "                else:\n",
    "                    isTrain = np.concatenate((isTrain,np.zeros(numEx)))\n",
    "\n",
    "        featData['isTrain'] = isTrain\n",
    "        ngramData['isTrain'] = isTrain\n",
    "\n",
    "        # train HD model\n",
    "        allGest = ngramData['gesture'].unique()\n",
    "        \n",
    "        # loop through all HDC adaptive thresholds\n",
    "        for atIdx,at in enumerate(adaptThreshold):\n",
    "            AM = hdc.Memory(D)\n",
    "            for g in allGest:\n",
    "                ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTrain'] == 1) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "                AM.train_sub_cluster(ng,vClass=g,threshold=at)\n",
    "                AM.prune(min=5)\n",
    "\n",
    "            for g in allGest:\n",
    "                ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTrain'] == 1) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "                AM.train_sub_cluster(ng,vClass=g,threshold=at)\n",
    "                AM.prune(min=5)\n",
    "\n",
    "            # collect testing data and perform inference\n",
    "            testNgram = ngramData.loc[(ngramData['isTrain'] == 0)].iloc[:,0:D]\n",
    "            testLabel = ngramData.loc[(ngramData['isTrain'] == 0)].iloc[:,D]\n",
    "#             AM.prune(min=5)\n",
    "            label,sim = AM.match(np.asarray(testNgram),bipolar=True)\n",
    "            accHDC[tpIdx,atIdx,n] = (label == np.asarray(testLabel)).sum()/len(label)\n",
    "            numHDC[tpIdx,atIdx,n] = len(AM.classes)\n",
    "\n",
    "        # train and test SVM model\n",
    "        clf = svm.SVC(decision_function_shape='ovo',kernel='linear',C=1)\n",
    "        clf.fit(featData.loc[featData['isTrain'] == 1].iloc[:,0:numFeat],featData.loc[featData['isTrain'] == 1].iloc[:,numFeat])\n",
    "        yhat = clf.predict(featData.loc[featData['isTrain'] == 0].iloc[:,0:numFeat])\n",
    "        accSVM[tpIdx,n] = accuracy_score(yhat,featData.loc[featData['isTrain'] == 0].iloc[:,numFeat])\n",
    "        numSVM[tpIdx,n] = len(clf.support_)\n",
    "        \n",
    "        endTime = time.time()\n",
    "        elapsedTime = (elapsedTime*n/(n+1)) + ((endTime-startTime)/(n+1))\n",
    "        print('Finished iteration %d, average time %f seconds\\r' % (n+1, elapsedTime), end=\"\")\n",
    "    print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99230769, 0.99639423])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accSVM,axis=accSVM.ndim-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([305. , 709.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(numSVM,axis=numSVM.ndim-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95745192, 0.91274038],\n",
       "       [0.95817308, 0.91514423]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accHDC,axis=accHDC.ndim-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13., 65.],\n",
       "       [18., 65.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(numHDC,axis=numHDC.ndim-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matOut = {}\n",
    "# matOut['accSVM'] = accSVM\n",
    "# matOut['accHDC'] = accHDC\n",
    "# matOut['numSVM'] = numSVM\n",
    "# matOut['numHDC'] = numHDC\n",
    "# sio.savemat('s2_adapt.mat',matOut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
