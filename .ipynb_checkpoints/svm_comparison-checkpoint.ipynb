{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import hdc\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Subject 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3807de31b291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdStart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdEnd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mholdStart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mholdEnd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumEx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumEx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# location of all offline data\n",
    "dataDir = './emg_mat/offline/'\n",
    "\n",
    "baseExperiment = 1\n",
    "newExperiment = 3\n",
    "\n",
    "holdStart = 70\n",
    "holdEnd = 149\n",
    "D = 10000\n",
    "numFeat = 320\n",
    "\n",
    "numIter = 2\n",
    "\n",
    "numSVM = np.zeros((5,20,numIter))\n",
    "accSVM = np.zeros((5,20,numIter))\n",
    "accHDC = np.zeros((5,20,numIter))\n",
    "\n",
    "# for s in range(5):\n",
    "for s in [1]:\n",
    "    # subject labels are 1-indexed\n",
    "    subject = s + 1\n",
    "    print('Running Subject ' + str(subject))\n",
    "    \n",
    "    # load data from the two contexts\n",
    "    filename = dataDir + 'S' + str(subject) + 'E' + str(baseExperiment) + '.mat'\n",
    "    base = sio.loadmat(filename)['emgHD']\n",
    "    filename = dataDir + 'S' + str(subject) + 'E' + str(newExperiment) + '.mat'\n",
    "    new = sio.loadmat(filename)['emgHD']\n",
    "    \n",
    "    # get metatdata\n",
    "    numGest, numTrial = base.shape\n",
    "    numCh = base[0,0][2].shape[1]\n",
    "    numEx = holdEnd - holdStart + 1\n",
    "    \n",
    "    # separate training and testing dataframes\n",
    "    features = np.empty((numCh*5,0))\n",
    "    ngrams = np.empty((D,0))\n",
    "    labels = np.empty(0)\n",
    "    trials = np.empty(0)\n",
    "    context = np.empty(0)\n",
    "\n",
    "    # collect baseline data\n",
    "    \n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            trial = base[g,t]\n",
    "            feat = np.empty((0,numEx))\n",
    "            for i in range(5):\n",
    "                feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "            features = np.concatenate((features,feat),axis=1)\n",
    "            ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "            labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "            trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "            context = np.concatenate((context,0*np.ones(numEx)))\n",
    "    # collect new data\n",
    "    \n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            trial = new[g,t]\n",
    "            feat = np.empty((0,numEx))\n",
    "            for i in range(5):\n",
    "                feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "            features = np.concatenate((features,feat),axis=1)\n",
    "            ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "            labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "            trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "            context = np.concatenate((context,1*np.ones(numEx)))\n",
    "\n",
    "    # create dataframe for features\n",
    "    featCols = ['feature' + str(i) for i in range(features.shape[0])]\n",
    "    featData = pd.DataFrame(features.T,columns=featCols)\n",
    "    featData['gesture'] = labels\n",
    "    featData['trial'] = trials\n",
    "    featData['context'] = context\n",
    "\n",
    "    # create dataframe for ngrams\n",
    "    ngramCols = ['hv' + str(i) for i in range(ngrams.shape[0])]\n",
    "    ngramData = pd.DataFrame(ngrams.T,columns=ngramCols)\n",
    "    ngramData['gesture'] = labels\n",
    "    ngramData['trial'] = trials\n",
    "    ngramData['context'] = context\n",
    "    \n",
    "    testPercentage = np.linspace(0.05,1,20)\n",
    "    for tpIdx,tp in enumerate(testPercentage):\n",
    "        # iterate through to get averages (cross-validation)\n",
    "        for n in range(numIter):\n",
    "            isTest = np.empty(0)\n",
    "            testTrials = np.random.randint(0,numTrial,numGest)\n",
    "            for g in range(numGest):\n",
    "                for t in range(numTrial):\n",
    "                    if t == testTrials[g]:\n",
    "                        isTest = np.concatenate((isTest,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx)), np.zeros(numEx - int(round(tp*numEx)))))))\n",
    "                    else:\n",
    "                        isTest = np.concatenate((isTest,np.zeros(numEx)))\n",
    "            testTrials = np.random.randint(0,numTrial,numGest)\n",
    "            for g in range(numGest):\n",
    "                for t in range(numTrial):\n",
    "                    if t == testTrials[g]:\n",
    "                        isTest = np.concatenate((isTest,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx)), np.zeros(numEx - int(round(tp*numEx)))))))\n",
    "                    else:\n",
    "                        isTest = np.concatenate((isTest,np.zeros(numEx)))\n",
    "\n",
    "            featData['isTest'] = isTest\n",
    "            ngramData['isTest'] = isTest\n",
    "\n",
    "            # train HD model\n",
    "            allGest = ngramData['gesture'].unique()\n",
    "            AM = hdc.Memory(D)\n",
    "            for g in allGest:\n",
    "    #             ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 0) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "                ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 1) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "                AM.train(ng,vClass=g,vClust=0)\n",
    "\n",
    "            for g in allGest:\n",
    "    #             ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 0) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "                ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 1) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "                AM.train(ng,vClass=g,vClust=1)\n",
    "\n",
    "            # collect testing data and perform inference\n",
    "            testNgram = ngramData.loc[(ngramData['isTest'] == 0)].iloc[:,0:D]\n",
    "            testLabel = ngramData.loc[(ngramData['isTest'] == 0)].iloc[:,D]\n",
    "\n",
    "            label,sim = AM.match(np.asarray(testNgram),bipolar=True)\n",
    "            accHDC[s,tpIdx,n] = (label == np.asarray(testLabel)).sum()/len(label)\n",
    "            acc = accHDC[s,np.nonzero(accHDC[s,tpIdx,:])].mean()\n",
    "            print('\\t HDC Iteration %d: Accuracy = %f'%(n+1,acc))\n",
    "\n",
    "            # train and test SVM model\n",
    "            clf = svm.SVC(decision_function_shape='ovo',kernel='linear',C=10)\n",
    "    #         clf.fit(featData.loc[featData['isTest'] == 0].iloc[:,0:numFeat],featData.loc[featData['isTest'] == 0].iloc[:,numFeat])\n",
    "            clf.fit(featData.loc[featData['isTest'] == 1].iloc[:,0:numFeat],featData.loc[featData['isTest'] == 1].iloc[:,numFeat])\n",
    "    #         yhat = clf.predict(featData.loc[featData['isTest'] == 1].iloc[:,0:numFeat])\n",
    "    #         accSVM[s,n] = accuracy_score(yhat,featData.loc[featData['isTest'] == 1].iloc[:,numFeat])\n",
    "            yhat = clf.predict(featData.loc[featData['isTest'] == 0].iloc[:,0:numFeat])\n",
    "            accSVM[s,tpIdx,n] = accuracy_score(yhat,featData.loc[featData['isTest'] == 0].iloc[:,numFeat])\n",
    "            numSVM[s,tpIdx,n] = len(clf.support_)\n",
    "            acc = accSVM[s,np.nonzero(accSVM[s,tpIdx,:])].mean()\n",
    "            num = numSVM[s,np.nonzero(numSVM[s,tpIdx,:])].mean()\n",
    "            print('\\t Iteration %d: SVM Accuracy = %f'%(n+1,acc))\n",
    "        \n",
    "# #         # batch train and test LDA model\n",
    "# #         clf = LinearDiscriminantAnalysis()\n",
    "# #         clf.fit(Xtrain,ytrain)\n",
    "# #         yhat = clf.predict(Xtest)\n",
    "# #         print('\\t Iteration %d: Accuracy = %f\\r'%(n+1,accuracy_score(yhat,ytest)),end=\"\")\n",
    "# # #         accSVM[s,n] = accuracy_score(yhat,ytest)\n",
    "# # #         numSVM[s,n] = len(clf.support_)\n",
    "# #         print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(tp*numEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
