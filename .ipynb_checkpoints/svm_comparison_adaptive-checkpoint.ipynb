{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import hdc\n",
    "\n",
    "import importlib\n",
    "importlib.reload(hdc)\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data for Subject 2\n",
      "Running with 0.050000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.100000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.150000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.200000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.250000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.300000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.350000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.400000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.450000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.500000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.550000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.600000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.650000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.700000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.750000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.800000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.850000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.900000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 0.950000 of trial for training\n",
      "Finished iteration 0\n",
      "Running with 1.000000 of trial for training\n",
      "Finished iteration 0\n"
     ]
    }
   ],
   "source": [
    "# location of all offline data\n",
    "dataDir = './emg_mat/offline/'\n",
    "\n",
    "baseExperiment = 1\n",
    "newExperiment = 3\n",
    "\n",
    "holdStart = 70\n",
    "holdEnd = 149\n",
    "D = 10000\n",
    "numFeat = 320\n",
    "numEx = holdEnd - holdStart + 1\n",
    "\n",
    "numIter = 1\n",
    "testPercentage = np.linspace(0.05,1,20)\n",
    "adaptThreshold = np.linspace(0.05,0.8,16)\n",
    "\n",
    "numSVM = np.zeros((5,len(testPercentage),numIter))\n",
    "accSVM = np.zeros((5,len(testPercentage),numIter))\n",
    "\n",
    "numHDC = np.zeros((5,len(testPercentage),len(adaptThreshold),numIter))\n",
    "accHDC = np.zeros((5,len(testPercentage),len(adaptThreshold),numIter))\n",
    "\n",
    "# for s in range(5):\n",
    "for s in [1]:\n",
    "    # subject labels are 1-indexed\n",
    "    subject = s + 1\n",
    "    print('Gathering data for Subject ' + str(subject))\n",
    "    \n",
    "    # load data from the two contexts\n",
    "    filename = dataDir + 'S' + str(subject) + 'E' + str(baseExperiment) + '.mat'\n",
    "    base = sio.loadmat(filename)['emgHD']\n",
    "    filename = dataDir + 'S' + str(subject) + 'E' + str(newExperiment) + '.mat'\n",
    "    new = sio.loadmat(filename)['emgHD']\n",
    "    \n",
    "    # get metatdata\n",
    "    numGest, numTrial = base.shape\n",
    "    numCh = base[0,0][2].shape[1]\n",
    "    \n",
    "    # separate training and testing dataframes\n",
    "    features = np.empty((numCh*5,0))\n",
    "    ngrams = np.empty((D,0))\n",
    "    labels = np.empty(0)\n",
    "    trials = np.empty(0)\n",
    "    context = np.empty(0)\n",
    "\n",
    "    # collect baseline data\n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            trial = base[g,t]\n",
    "            feat = np.empty((0,numEx))\n",
    "            for i in range(5):\n",
    "                feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "            features = np.concatenate((features,feat),axis=1)\n",
    "            ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "            labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "            trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "            context = np.concatenate((context,0*np.ones(numEx)))\n",
    "    \n",
    "    # collect new data\n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            trial = new[g,t]\n",
    "            feat = np.empty((0,numEx))\n",
    "            for i in range(5):\n",
    "                feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "            features = np.concatenate((features,feat),axis=1)\n",
    "            ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "            labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "            trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "            context = np.concatenate((context,1*np.ones(numEx)))\n",
    "\n",
    "    # create dataframe for features\n",
    "    featCols = ['feature' + str(i) for i in range(features.shape[0])]\n",
    "    featData = pd.DataFrame(features.T,columns=featCols)\n",
    "    featData['gesture'] = labels\n",
    "    featData['trial'] = trials\n",
    "    featData['context'] = context\n",
    "\n",
    "    # create dataframe for ngrams\n",
    "    ngramCols = ['hv' + str(i) for i in range(ngrams.shape[0])]\n",
    "    ngramData = pd.DataFrame(ngrams.T,columns=ngramCols)\n",
    "    ngramData['gesture'] = labels\n",
    "    ngramData['trial'] = trials\n",
    "    ngramData['context'] = context\n",
    "    \n",
    "    for tpIdx,tp in enumerate(testPercentage):\n",
    "        print('Running with %f of trial for training' % (tp))\n",
    "        # iterate through to get averages (cross-validation)\n",
    "        for n in range(numIter):\n",
    "            isTest = np.empty(0)\n",
    "            testTrials = np.random.randint(0,numTrial,numGest)\n",
    "            for g in range(numGest):\n",
    "                for t in range(numTrial):\n",
    "                    if t == testTrials[g]:\n",
    "                        isTest = np.concatenate((isTest,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "                    else:\n",
    "                        isTest = np.concatenate((isTest,np.zeros(numEx)))\n",
    "            testTrials = np.random.randint(0,numTrial,numGest)\n",
    "            for g in range(numGest):\n",
    "                for t in range(numTrial):\n",
    "                    if t == testTrials[g]:\n",
    "                        isTest = np.concatenate((isTest,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "                    else:\n",
    "                        isTest = np.concatenate((isTest,np.zeros(numEx)))\n",
    "\n",
    "            featData['isTest'] = isTest\n",
    "            ngramData['isTest'] = isTest\n",
    "\n",
    "            # train HD model\n",
    "            allGest = ngramData['gesture'].unique()\n",
    "            \n",
    "            for atIdx,at in enumerate(adaptThreshold):\n",
    "                AM = hdc.Memory(D)\n",
    "                for g in allGest:\n",
    "        #             ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 0) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "                    ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 1) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "    #                 AM.train(ng,vClass=g,vClust=0)\n",
    "                    AM.train_sub_cluster(ng,vClass=g,threshold=at)\n",
    "\n",
    "                for g in allGest:\n",
    "        #             ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 0) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "                    ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 1) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "    #                 AM.train(ng,vClass=g,vClust=1)\n",
    "                    AM.train_sub_cluster(ng,vClass=g,threshold=at)\n",
    "\n",
    "                # collect testing data and perform inference\n",
    "                testNgram = ngramData.loc[(ngramData['isTest'] == 0)].iloc[:,0:D]\n",
    "                testLabel = ngramData.loc[(ngramData['isTest'] == 0)].iloc[:,D]\n",
    "                AM.prune(min=2)\n",
    "                label,sim = AM.match(np.asarray(testNgram),bipolar=True)\n",
    "                accHDC[s,tpIdx,atIdx,n] = (label == np.asarray(testLabel)).sum()/len(label)\n",
    "                numHDC[s,tpIdx,atIdx,n] = len(AM.classes)\n",
    "    #             acc = accHDC[s,tpIdx,np.nonzero(accHDC[s,tpIdx,:])].mean()\n",
    "    #             print('\\t HDC Iteration %d: Accuracy = %f'%(n+1,acc))\n",
    "\n",
    "            # train and test SVM model\n",
    "            clf = svm.SVC(decision_function_shape='ovo',kernel='linear',C=1)\n",
    "    #         clf.fit(featData.loc[featData['isTest'] == 0].iloc[:,0:numFeat],featData.loc[featData['isTest'] == 0].iloc[:,numFeat])\n",
    "            clf.fit(featData.loc[featData['isTest'] == 1].iloc[:,0:numFeat],featData.loc[featData['isTest'] == 1].iloc[:,numFeat])\n",
    "    #         yhat = clf.predict(featData.loc[featData['isTest'] == 1].iloc[:,0:numFeat])\n",
    "    #         accSVM[s,n] = accuracy_score(yhat,featData.loc[featData['isTest'] == 1].iloc[:,numFeat])\n",
    "            yhat = clf.predict(featData.loc[featData['isTest'] == 0].iloc[:,0:numFeat])\n",
    "            accSVM[s,tpIdx,n] = accuracy_score(yhat,featData.loc[featData['isTest'] == 0].iloc[:,numFeat])\n",
    "            numSVM[s,tpIdx,n] = len(clf.support_)\n",
    "#             acc = accSVM[s,tpIdx,np.nonzero(accSVM[s,tpIdx,:])].mean()\n",
    "#             num = numSVM[s,tpIdx,np.nonzero(numSVM[s,tpIdx,:])].mean()\n",
    "#             print('\\t Iteration %d: SVM Accuracy = %f'%(n+1,acc))\n",
    "\n",
    "            print('Finished iteration %d\\r' % (n), end=\"\")\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matOut = {}\n",
    "matOut['accSVM'] = accSVM\n",
    "matOut['accHDC'] = accHDC\n",
    "matOut['numSVM'] = numSVM\n",
    "matOut['numHDC'] = numHDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat('s2_adaptive_test.mat',matOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
