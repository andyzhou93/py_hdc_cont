{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import hdc\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data for Subject 1\n",
      "Running with 0.050000 of trial for training\n",
      "Finished iteration 49\n",
      "Running with 0.100000 of trial for training\n",
      "Finished iteration 49\n",
      "Running with 0.150000 of trial for training\n",
      "Finished iteration 49\n",
      "Running with 0.200000 of trial for training\n",
      "Finished iteration 49\n",
      "Running with 0.250000 of trial for training\n",
      "Finished iteration 49\n",
      "Running with 0.300000 of trial for training\n",
      "Finished iteration 49\n",
      "Running with 0.350000 of trial for training\n",
      "Finished iteration 49\n",
      "Running with 0.400000 of trial for training\n",
      "Finished iteration 2\r"
     ]
    }
   ],
   "source": [
    "# location of all offline data\n",
    "dataDir = './emg_mat/offline/'\n",
    "\n",
    "baseExperiment = 1\n",
    "newExperiment = 3\n",
    "\n",
    "holdStart = 70\n",
    "holdEnd = 149\n",
    "D = 10000\n",
    "numFeat = 320\n",
    "numEx = holdEnd - holdStart + 1\n",
    "\n",
    "numIter = 50\n",
    "\n",
    "numSVM = np.zeros((5,20,numIter))\n",
    "accSVM = np.zeros((5,20,numIter))\n",
    "accHDC = np.zeros((5,20,numIter))\n",
    "\n",
    "for s in range(5):\n",
    "    # subject labels are 1-indexed\n",
    "    subject = s + 1\n",
    "    print('Gathering data for Subject ' + str(subject))\n",
    "    \n",
    "    # load data from the two contexts\n",
    "    filename = dataDir + 'S' + str(subject) + 'E' + str(baseExperiment) + '.mat'\n",
    "    base = sio.loadmat(filename)['emgHD']\n",
    "    filename = dataDir + 'S' + str(subject) + 'E' + str(newExperiment) + '.mat'\n",
    "    new = sio.loadmat(filename)['emgHD']\n",
    "    \n",
    "    # get metatdata\n",
    "    numGest, numTrial = base.shape\n",
    "    numCh = base[0,0][2].shape[1]\n",
    "    \n",
    "    # separate training and testing dataframes\n",
    "    features = np.empty((numCh*5,0))\n",
    "    ngrams = np.empty((D,0))\n",
    "    labels = np.empty(0)\n",
    "    trials = np.empty(0)\n",
    "    context = np.empty(0)\n",
    "\n",
    "    # collect baseline data\n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            trial = base[g,t]\n",
    "            feat = np.empty((0,numEx))\n",
    "            for i in range(5):\n",
    "                feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "            features = np.concatenate((features,feat),axis=1)\n",
    "            ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "            labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "            trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "            context = np.concatenate((context,0*np.ones(numEx)))\n",
    "    \n",
    "    # collect new data\n",
    "    for g in range(numGest):\n",
    "        for t in range(numTrial):\n",
    "            trial = new[g,t]\n",
    "            feat = np.empty((0,numEx))\n",
    "            for i in range(5):\n",
    "                feat = np.concatenate((feat,trial[2][(holdStart+i):(holdEnd+i+1),:].T),axis=0)\n",
    "            features = np.concatenate((features,feat),axis=1)\n",
    "            ngrams = np.concatenate((ngrams,trial[3][:,holdStart:holdEnd+1]),axis=1)\n",
    "            labels = np.concatenate((labels,g*np.ones(numEx)))\n",
    "            trials = np.concatenate((trials,t*np.ones(numEx)))\n",
    "            context = np.concatenate((context,1*np.ones(numEx)))\n",
    "\n",
    "    # create dataframe for features\n",
    "    featCols = ['feature' + str(i) for i in range(features.shape[0])]\n",
    "    featData = pd.DataFrame(features.T,columns=featCols)\n",
    "    featData['gesture'] = labels\n",
    "    featData['trial'] = trials\n",
    "    featData['context'] = context\n",
    "\n",
    "    # create dataframe for ngrams\n",
    "    ngramCols = ['hv' + str(i) for i in range(ngrams.shape[0])]\n",
    "    ngramData = pd.DataFrame(ngrams.T,columns=ngramCols)\n",
    "    ngramData['gesture'] = labels\n",
    "    ngramData['trial'] = trials\n",
    "    ngramData['context'] = context\n",
    "    \n",
    "    testPercentage = np.linspace(0.05,1,20)\n",
    "    for tpIdx,tp in enumerate(testPercentage):\n",
    "        print('Running with %f of trial for training' % (tp))\n",
    "        # iterate through to get averages (cross-validation)\n",
    "        for n in range(numIter):\n",
    "            isTest = np.empty(0)\n",
    "            testTrials = np.random.randint(0,numTrial,numGest)\n",
    "            for g in range(numGest):\n",
    "                for t in range(numTrial):\n",
    "                    if t == testTrials[g]:\n",
    "                        isTest = np.concatenate((isTest,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "                    else:\n",
    "                        isTest = np.concatenate((isTest,np.zeros(numEx)))\n",
    "            testTrials = np.random.randint(0,numTrial,numGest)\n",
    "            for g in range(numGest):\n",
    "                for t in range(numTrial):\n",
    "                    if t == testTrials[g]:\n",
    "                        isTest = np.concatenate((isTest,np.random.permutation(np.concatenate((np.ones(int(round(tp*numEx))), -np.ones(numEx - int(round(tp*numEx))))))))\n",
    "                    else:\n",
    "                        isTest = np.concatenate((isTest,np.zeros(numEx)))\n",
    "\n",
    "            featData['isTest'] = isTest\n",
    "            ngramData['isTest'] = isTest\n",
    "\n",
    "            # train HD model\n",
    "            allGest = ngramData['gesture'].unique()\n",
    "            AM = hdc.Memory(D)\n",
    "            for g in allGest:\n",
    "    #             ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 0) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "                ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 1) & (ngramData['context'] == 0)].iloc[:,0:D])\n",
    "                AM.train(ng,vClass=g,vClust=0)\n",
    "\n",
    "            for g in allGest:\n",
    "    #             ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 0) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "                ng = np.asarray(ngramData.loc[(ngramData['gesture'] == g) & (ngramData['isTest'] == 1) & (ngramData['context'] == 1)].iloc[:,0:D])\n",
    "                AM.train(ng,vClass=g,vClust=1)\n",
    "\n",
    "            # collect testing data and perform inference\n",
    "            testNgram = ngramData.loc[(ngramData['isTest'] == 0)].iloc[:,0:D]\n",
    "            testLabel = ngramData.loc[(ngramData['isTest'] == 0)].iloc[:,D]\n",
    "\n",
    "            label,sim = AM.match(np.asarray(testNgram),bipolar=True)\n",
    "            accHDC[s,tpIdx,n] = (label == np.asarray(testLabel)).sum()/len(label)\n",
    "#             acc = accHDC[s,tpIdx,np.nonzero(accHDC[s,tpIdx,:])].mean()\n",
    "#             print('\\t HDC Iteration %d: Accuracy = %f'%(n+1,acc))\n",
    "\n",
    "            # train and test SVM model\n",
    "            clf = svm.SVC(decision_function_shape='ovo',kernel='linear',C=1)\n",
    "    #         clf.fit(featData.loc[featData['isTest'] == 0].iloc[:,0:numFeat],featData.loc[featData['isTest'] == 0].iloc[:,numFeat])\n",
    "            clf.fit(featData.loc[featData['isTest'] == 1].iloc[:,0:numFeat],featData.loc[featData['isTest'] == 1].iloc[:,numFeat])\n",
    "    #         yhat = clf.predict(featData.loc[featData['isTest'] == 1].iloc[:,0:numFeat])\n",
    "    #         accSVM[s,n] = accuracy_score(yhat,featData.loc[featData['isTest'] == 1].iloc[:,numFeat])\n",
    "            yhat = clf.predict(featData.loc[featData['isTest'] == 0].iloc[:,0:numFeat])\n",
    "            accSVM[s,tpIdx,n] = accuracy_score(yhat,featData.loc[featData['isTest'] == 0].iloc[:,numFeat])\n",
    "            numSVM[s,tpIdx,n] = len(clf.support_)\n",
    "#             acc = accSVM[s,tpIdx,np.nonzero(accSVM[s,tpIdx,:])].mean()\n",
    "#             num = numSVM[s,tpIdx,np.nonzero(numSVM[s,tpIdx,:])].mean()\n",
    "#             print('\\t Iteration %d: SVM Accuracy = %f'%(n+1,acc))\n",
    "\n",
    "            print('Finished iteration %d\\r' % (n), end=\"\")\n",
    "        print('')\n",
    "        \n",
    "# #         # batch train and test LDA model\n",
    "# #         clf = LinearDiscriminantAnalysis()\n",
    "# #         clf.fit(Xtrain,ytrain)\n",
    "# #         yhat = clf.predict(Xtest)\n",
    "# #         print('\\t Iteration %d: Accuracy = %f\\r'%(n+1,accuracy_score(yhat,ytest)),end=\"\")\n",
    "# # #         accSVM[s,n] = accuracy_score(yhat,ytest)\n",
    "# # #         numSVM[s,n] = len(clf.support_)\n",
    "# #         print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "axs[0].set_xlabel('Percentage of trial for training')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].plot(testPercentage,np.mean(accHDC,axis=(0,2)),color='tab:blue')\n",
    "axs[0].plot(testPercentage,np.mean(accSVM,axis=(0,2)),color='tab:red')\n",
    "\n",
    "axs[1].set_xlabel('Percentage of trial for training')\n",
    "axs[1].set_ylabel('Memory footprint (bits)')\n",
    "axs[1].plot(testPercentage,np.mean(numSVM,axis=(0,2))*320*6,color='tab:red',linestyle=':')\n",
    "axs[1].plot(testPercentage,np.ones(len(testPercentage))*260000,color='tab:blue',linestyle=':')\n",
    "plt.ylim((0,max(np.mean(numSVM,axis=(0,2))*320*6)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
